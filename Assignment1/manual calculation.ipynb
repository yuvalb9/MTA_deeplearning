{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT = np.asmatrix([6.15840302,-2.86995972])\n",
    "TARGET = np.asmatrix([5.56039031])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the Signoid function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z, prime=False):\n",
    "    if prime:\n",
    "        f = sigmoid(z, prime=False)\n",
    "        return np.multiply(f , ( 1.0 - f ) )\n",
    "\n",
    "    return 1.0/(1.0 + np.exp(-1.0 * z))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up weights\n",
    "\n",
    "The network is built as follows:\n",
    "1. Input layer - 2 neurons\n",
    "2. 1st hidden layer - 4 neurons\n",
    "3. 2nd hidden layer - 2 neurons\n",
    "4. Output layer - 1 neurons\n",
    "\n",
    "there for we have 3 weights matrices:\n",
    "- W1 - between input and 1st hidden.\n",
    "- W2 - between 1st hidden and 2nd hidden.\n",
    "- W3 - between 2nd hidden and output layer.\n",
    "\n",
    "The wieght matrix is in size : (input nodes + 1 for bias ) X (amount of neurons in current layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape (3, 4)  - 2 input node + 1 bias to 4 neurons in 1st hidden layer\n",
    "W1 = np.asmatrix([[0.51639863,0.57066759,0.02847423,0.17152166],\n",
    "[0.68527698,0.83389686,0.30696622,0.89361308],\n",
    "[0.72154386,0.18993895,0.55422759,0.35213195]])\n",
    "\n",
    "# shape (5, 3)  - 4 input node + 1 bias to 3 neurons in 2nd hidden layer\n",
    "W2 = np.asmatrix([[0.1818924,0.78560176,0.96548322],\n",
    "[0.23235366,0.08356143,0.60354842],\n",
    "[0.72899276,0.27623883,0.68530633],\n",
    "[0.51786747,0.04848454,0.13786924],\n",
    "[0.18696743,0.9943179,0.5206654]])\n",
    "\n",
    "# shape (4, 1)  - 3 input node + 1 bias to 1neurons in output layer\n",
    "W3 = np.asmatrix([[0.57878954],\n",
    "[0.73481906],\n",
    "[0.54196177],\n",
    "[0.91315356]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.        ,  6.15840302, -2.86995972]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first - pad a bias to the input data\n",
    "values_rows = INPUT.shape[0]\n",
    "bias_and_values = np.concatenate(  [np.ones((values_rows, 1)) , INPUT ], axis=1)\n",
    "bias_and_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.66580864,  5.1610234 ,  0.32828507,  4.66414664]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate pre activation\n",
    "hidden_layer_1_pre_activation = np.dot(bias_and_values, W1)\n",
    "hidden_layer_1_pre_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.93497869,  0.99429689,  0.58134205,  0.99066075]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate post activation\n",
    "hidden_layer_1_post_activation = sigmoid( hidden_layer_1_pre_activation )\n",
    "layers_output.append(hidden_layer_1_post_activation)\n",
    "hidden_layer_1_post_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.        ,  0.93497869,  0.99429689,  0.58134205,  0.99066075]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_rows = hidden_layer_1_post_activation.shape[0]\n",
    "bias_and_values = np.concatenate(  [np.ones((values_rows, 1)) , hidden_layer_1_post_activation ], axis=1)\n",
    "bias_and_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.83344648,  0.89581924,  0.94306033]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate pre activation\n",
    "hidden_layer_2_pre_activation = np.dot(bias_and_values, W2)\n",
    "hidden_layer_2_pre_activation\n",
    "# calculate post activation\n",
    "hidden_layer_2_post_activation = sigmoid( hidden_layer_2_pre_activation )\n",
    "layers_output.append(hidden_layer_2_post_activation)\n",
    "hidden_layer_2_post_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.        ,  0.83344648,  0.89581924,  0.94306033]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_rows = hidden_layer_2_post_activation.shape[0]\n",
    "bias_and_values = np.concatenate(  [np.ones((values_rows, 1)) , hidden_layer_2_post_activation ], axis=1)\n",
    "bias_and_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.92675509]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate pre activation\n",
    "output_layer_pre_activation = np.dot(bias_and_values, W3)\n",
    "\n",
    "# calculate post activation\n",
    "output_layer_post_activation = sigmoid( output_layer_pre_activation )\n",
    "layers_output.append(output_layer_post_activation)\n",
    "output_layer_post_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propogation\n",
    "\n",
    "We've got the feed forward results of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[ 0.93497869,  0.99429689,  0.58134205,  0.99066075]]),\n",
       " matrix([[ 0.83344648,  0.89581924,  0.94306033]]),\n",
       " matrix([[ 0.92675509]])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_delta = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1.06656323, -1.09354832, -1.08391422, -1.07623676],\n",
       "        [-1.01510249, -1.05623298, -1.04145654, -1.02975454],\n",
       "        [-1.07734337, -1.10127413, -1.09274146, -1.08593303],\n",
       "        [-0.94691021, -1.00562372, -0.98434797, -0.96764429]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from https://sudeepraja.github.io/Neural/\n",
    "\n",
    "values_rows = hidden_layer_2_post_activation.shape[0]\n",
    "hidden_layer_2_post_activation_with_bias = np.concatenate(  [np.ones((values_rows, 1)) , hidden_layer_2_post_activation ], axis=1)\n",
    "delta_out =  np.multiply ( output_layer_post_activation - TARGET, sigmoid( np.dot( W3, hidden_layer_2_post_activation_with_bias)  , prime=True))\n",
    "\n",
    "layers_delta.append(delta_out)\n",
    "delta_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
